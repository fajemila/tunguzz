{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TungMTLstm_GRu.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUa8gf8A0zho",
        "outputId": "270e507d-2031-4624-e508-f7a4733e43cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Xms4lk0ptP"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import spacy\n",
        "import string\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "import timeit\n",
        "\n",
        "import collections\n",
        "from IPython.display import HTML, IFrame\n",
        "\n",
        "from textblob import TextBlob\n",
        "from torchtext import data\n",
        "import torch"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPXq5TNjfBjO"
      },
      "source": [
        "import random\r\n",
        "SEED  = 2020\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK9FpMfyqSOU"
      },
      "source": [
        "def generate_bigrams(x):\r\n",
        "    n_grams = set(zip(*[x[i:] for i in range(2)]))\r\n",
        "    for n_gram in n_grams:\r\n",
        "        x.append(' '.join(n_gram))\r\n",
        "    return x"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIWJM1ur0ptW",
        "outputId": "483cce09-4884-438e-b645-019a6513bdc4"
      },
      "source": [
        "tokenizer = lambda x: str(x).translate(str.maketrans('', '', string.punctuation)).strip().split()\n",
        "\n",
        "# Step one defination of our fields. \n",
        "ID = data.Field()\n",
        "TEXT = data.Field(sequential=True, lower=True, tokenize=tokenizer,include_lengths = True)\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "print(\"loading from csv ...\")\n",
        "tv_datafields = [(None,None),(\"text\", TEXT), (\"label\", LABEL)]\n",
        "\n",
        "# Step two construction our dataset.\n",
        "train_data = data.TabularDataset(path='drive/MyDrive/tunguz/Train.csv',format=\"csv\",\n",
        "                                                skip_header=True, fields=tv_datafields,)\n",
        "test_data = data.TabularDataset(path='drive/MyDrive/tunguz/Test.csv', format=\"csv\",\n",
        "                                                skip_header=True, fields=[('ID',ID),(\"text\", TEXT)])\n",
        "print(train_data[0].__dict__.keys())"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading from csv ...\n",
            "dict_keys(['text', 'label'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8Iqsdor0ptg",
        "outputId": "7025c65a-16f6-4b13-a2fe-3184336a8345"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 70000\n",
            "Number of testing examples: 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYeQ99F70ptk",
        "outputId": "08700dd7-efee-4ac1-ec9f-243b3bd8ec88"
      },
      "source": [
        "print(vars(train_data.examples[2]))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['bereau', 'degage', 'nathef', 'ya', 'slim', 'walahi', 'ya7chiw', 'fih', 'jma3a', 'lem3amel', '3lihom', 'walah', 'kit', 'jib', 'messi', 'lana3mlou', 'chay', '7amlet', 'nathafa', 'fil', 'bureaux', 'ca', 'jam3iya', '3ari9a', 'mel', '3am', '94', 'bdet', 'da5la', 'fi', '7it', 'choufelna', 'hal', 'mochkla', 'belehi', 'te5na9na', 'mel', 'fada', 'tous', 'les', 'Ã©quipe', 'mergine', 'fina', 'ken', 'jit', 'kifek', 'walah', 'maye5lsouch', 'wi3adiw', '3am', 'jaych', 'bech', 'yetrabaw', 'elkoura', 'fi', 'se9ik', 'enti', 'en9eth', 'jam3iya', 'ya', 'slim', 'wna3ref', 'tnajim', 'ta3melha'], 'label': '-1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYxFxWf70ptn"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(split_ratio=0.9,random_state = random.seed(202))"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7pWaE_O0ptp",
        "outputId": "b387f793-6136-4af5-9f62-97fcc024290f"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 63000\n",
            "Number of validation examples: 7000\n",
            "Number of testing examples: 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkimwJXW0ptq",
        "outputId": "b9ce7905-1698-4109-a879-afb02a226949"
      },
      "source": [
        "print(vars(valid_data.examples[2]))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['billahi', 'bara', 'ara', 'imninn', 'itjiboo', 'fi', 'iflouskimm', 'ow', 'cof', '7ata', 'min', 'jimhorr', 'karhik', 'ow', 'ikrah', 'iflousik', 'ow', 'fadd', 'min', '7aja', 'manirb7oo', 'ila', 'mana3tiw', 'liflous', 'kima', 'ilyoma', 'il', 'pilanti', 'ili', 'ta3t', 'lil', 'ca', 'mafamach', 'minha', 'ow', 'zid', 'intom', 'dija', 'itla3too', 'lil', 'play', 'off', 'ila', 'bil', 'iflouss', 'bara', 'i9bal', 'ma', 'ta7ki', '3ala', 'jimhor', 'ca', 'aana', 'in7ib', 'css', 'lakin', 'jomhorr', 'ca', 'ow', 'howa', 'johorr', 'ikbirrr', 'ara', 'rou7ikk', 'kifach', 'tik4ibb', '3alihimm', 'winti', 'ow3ithimm', 'bil', 'boutoula', 'fil', 'lo5ir', 'ma9aw', 'chinn', 'ow', 'ara', 'rou7ik', 'bama', 'tari9a', 'racha7t', 'lifri9i', 'lil', 'play', 'off'], 'label': '-1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpT1YodO0pts"
      },
      "source": [
        "MAX_VOCAB_SIZE = 20_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "ID.build_vocab(test_data)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCKgM2qfz6Xp",
        "outputId": "0621a5c7-ad70-4985-8fbf-1bde0fb9f287"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f520cd5e488>, {'1': 0, '-1': 1, '0': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YbKH5k50ptu",
        "outputId": "7597e90f-8343-40f1-8fa2-0736dec6bc2c"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 20002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvd7EfYC0ptx",
        "outputId": "f5cbf2ac-d3ba-4157-d18c-ada6c805b626"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('w', 17581), ('ya', 8112), ('fi', 7987), ('el', 7022), ('slim', 6401), ('rabi', 5801), ('si', 3263), ('ca', 2833), ('l', 2808), ('kol', 2806), ('bech', 2695), ('bravo', 2646), ('ma', 2490), ('m3ak', 2473), ('3la', 2443), ('ken', 2408), ('la', 2350), ('allah', 2220), ('slouma', 2035), ('il', 1977)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvNCMEnx0pt0",
        "outputId": "231654e0-be21-47aa-e82d-1c43981fd946"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'w', 'ya', 'fi', 'el', 'slim', 'rabi', 'si', 'ca']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqh0JFP00pt2"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), sort=False,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)\n",
        "test_iterator = data.Iterator(test_data,batch_size=BATCH_SIZE,\n",
        "                              device=device,train=False,sort=False,\n",
        "                              sort_within_batch=False)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oS98B_ZvYA5"
      },
      "source": [
        "class SpatialDropout(nn.Dropout2d):\r\n",
        "    def forward(self, x):\r\n",
        "        x = x.unsqueeze(2)    # (N, T, 1, K)\r\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\r\n",
        "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\r\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\r\n",
        "        x = x.squeeze(2)  # (N, T, K)\r\n",
        "        return x\r\n",
        "class NeuralNet(nn.Module):\r\n",
        "    def __init__(self, embedding_matrix, num_aux_targets):\r\n",
        "        super(NeuralNet, self).__init__()\r\n",
        "        embed_size = embedding_matrix.shape[1]\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\r\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\r\n",
        "        self.embedding.weight.requires_grad = False\r\n",
        "        self.embedding_dropout = SpatialDropout(0.3)\r\n",
        "        \r\n",
        "        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\r\n",
        "        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\r\n",
        "    \r\n",
        "        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\r\n",
        "        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\r\n",
        "        \r\n",
        "        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, 1)\r\n",
        "        self.linear_aux_out = nn.Linear(DENSE_HIDDEN_UNITS, num_aux_targets)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        h_embedding = self.embedding(x)\r\n",
        "        h_embedding = self.embedding_dropout(h_embedding)\r\n",
        "        \r\n",
        "        h_lstm1, _ = self.lstm1(h_embedding)\r\n",
        "        h_lstm2, _ = self.lstm2(h_lstm1)\r\n",
        "        \r\n",
        "        # global average pooling\r\n",
        "        avg_pool = torch.mean(h_lstm2, 1)\r\n",
        "        # global max pooling\r\n",
        "        max_pool, _ = torch.max(h_lstm2, 1)\r\n",
        "        \r\n",
        "        h_conc = torch.cat((max_pool, avg_pool), 1)\r\n",
        "        h_conc_linear1  = F.relu(self.linear1(h_conc))\r\n",
        "        h_conc_linear2  = F.relu(self.linear2(h_conc))\r\n",
        "        \r\n",
        "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\r\n",
        "        \r\n",
        "        result = self.linear_out(hidden)\r\n",
        "        aux_result = self.linear_aux_out(hidden)\r\n",
        "        out = torch.cat([result, aux_result], 1)\r\n",
        "        \r\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzC-d93mwTyv"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "\r\n",
        "class RNN(nn.Module):\r\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \r\n",
        "                 bidirectional, dropout, pad_idx):\r\n",
        "        \r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\r\n",
        "        \r\n",
        "        self.rnn = nn.LSTM(embedding_dim, \r\n",
        "                           hidden_dim, \r\n",
        "                           num_layers=n_layers, \r\n",
        "                           bidirectional=bidirectional, \r\n",
        "                           dropout=dropout)\r\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, text, text_lengths):\r\n",
        "        \r\n",
        "        #text = [sent len, batch size]\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(text))\r\n",
        "        \r\n",
        "        #embedded = [sent len, batch size, emb dim]\r\n",
        "        \r\n",
        "        #pack sequence\r\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(),enforce_sorted=False)\r\n",
        "        \r\n",
        "        packed_output, (hidden,cell) = self.rnn(packed_embedded)\r\n",
        "        \r\n",
        "        #unpack sequence\r\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\r\n",
        "\r\n",
        "        #output = [sent len, batch size, hid dim * num directions]\r\n",
        "        #output over padding tokens are zero tensors\r\n",
        "        \r\n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\r\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\r\n",
        "        #and apply dropout\r\n",
        "        \r\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\r\n",
        "                \r\n",
        "        #hidden = [batch size, hid dim * num directions]\r\n",
        "            \r\n",
        "        return self.fc(hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUfCwEUC0pt5"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        # self.rnn = nn.GRU(embedding_dim, \n",
        "        #                    hidden_dim, \n",
        "        #                    num_layers=n_layers, \n",
        "        #                    bidirectional=bidirectional, \n",
        "        #                    dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(),enforce_sorted=False)\n",
        "        \n",
        "        packed_output, (hidden,cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFFWhlk80pt8"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 3\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTPxw1ky0pt_",
        "outputId": "72e5f7d0-ccc1-47e2-a366-6a7fd22ad78c"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,311,883 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvAIPBzX0puB"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9XlH8JM0puG"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]]).cuda()"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmU_uJCn0puH"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        text, text_lengths = batch.text\n",
        "                \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVVYv5_10puI"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVdHzSzG0puJ"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwDvMy7p5wHh",
        "outputId": "7167a95c-2765-4cb4-9019-a6356c7b1ef6"
      },
      "source": [
        "N_EPOCHS = 10 #LSTM\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.620 | Train Acc: 71.89%\n",
            "\t Val. Loss: 0.575 |  Val. Acc: 74.90%\n",
            "Epoch: 02 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.580 | Train Acc: 74.18%\n",
            "\t Val. Loss: 0.540 |  Val. Acc: 76.73%\n",
            "Epoch: 03 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.548 | Train Acc: 76.19%\n",
            "\t Val. Loss: 0.512 |  Val. Acc: 78.13%\n",
            "Epoch: 04 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.520 | Train Acc: 77.48%\n",
            "\t Val. Loss: 0.505 |  Val. Acc: 78.53%\n",
            "Epoch: 05 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.500 | Train Acc: 78.59%\n",
            "\t Val. Loss: 0.498 |  Val. Acc: 79.28%\n",
            "Epoch: 06 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.481 | Train Acc: 79.71%\n",
            "\t Val. Loss: 0.497 |  Val. Acc: 79.11%\n",
            "Epoch: 07 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.462 | Train Acc: 80.46%\n",
            "\t Val. Loss: 0.492 |  Val. Acc: 79.54%\n",
            "Epoch: 08 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.447 | Train Acc: 81.31%\n",
            "\t Val. Loss: 0.488 |  Val. Acc: 79.74%\n",
            "Epoch: 09 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.429 | Train Acc: 82.03%\n",
            "\t Val. Loss: 0.503 |  Val. Acc: 79.91%\n",
            "Epoch: 10 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.415 | Train Acc: 82.43%\n",
            "\t Val. Loss: 0.509 |  Val. Acc: 79.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrnMCP3IhKCA"
      },
      "source": [
        "def predict(model, iterator, criterion):\r\n",
        "    \r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    final_outputs = []  \r\n",
        "    test_id = []  \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for batch in iterator:\r\n",
        "            text, text_lengths = batch.text\r\n",
        "            predictions = model(text,text_lengths).squeeze(1)\r\n",
        "            predictions = predictions.argmax(1, keepdim = True) \r\n",
        "                                   \r\n",
        "            final_outputs+=predictions.view(-1).cpu().data.numpy().tolist()\r\n",
        "            test_id+=batch.ID.view(-1).cpu().numpy().tolist()\r\n",
        "    return test_id,final_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpeu6tFehYZM"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\r\n",
        "\r\n",
        "test_,pred= predict(model,test_iterator, criterion)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5qHPbE3hebK"
      },
      "source": [
        "test_ = [ID.vocab.itos[i] for i in test_]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hBO44-ghkfG"
      },
      "source": [
        "submission = pd.DataFrame({'ID':test_,'label':pred})\r\n",
        "submission.label = submission.label.replace({2:0, 0:1, 1: -1})\r\n",
        "submission.to_csv('lstm.csv',index=False)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfUX58lj0puK",
        "outputId": "5f79377d-7d4a-4da2-d03a-85fac6a6615b"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.691 | Train Acc: 67.05%\n",
            "\t Val. Loss: 0.597 |  Val. Acc: 73.64%\n",
            "Epoch: 02 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.606 | Train Acc: 73.23%\n",
            "\t Val. Loss: 0.546 |  Val. Acc: 76.71%\n",
            "Epoch: 03 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.561 | Train Acc: 75.59%\n",
            "\t Val. Loss: 0.517 |  Val. Acc: 78.06%\n",
            "Epoch: 04 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.522 | Train Acc: 77.79%\n",
            "\t Val. Loss: 0.504 |  Val. Acc: 78.39%\n",
            "Epoch: 05 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.491 | Train Acc: 79.41%\n",
            "\t Val. Loss: 0.489 |  Val. Acc: 79.49%\n",
            "Epoch: 06 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.466 | Train Acc: 80.65%\n",
            "\t Val. Loss: 0.481 |  Val. Acc: 79.97%\n",
            "Epoch: 07 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.445 | Train Acc: 81.79%\n",
            "\t Val. Loss: 0.481 |  Val. Acc: 80.06%\n",
            "Epoch: 08 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.425 | Train Acc: 82.63%\n",
            "\t Val. Loss: 0.480 |  Val. Acc: 80.36%\n",
            "Epoch: 09 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.408 | Train Acc: 83.51%\n",
            "\t Val. Loss: 0.484 |  Val. Acc: 80.48%\n",
            "Epoch: 10 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.393 | Train Acc: 84.09%\n",
            "\t Val. Loss: 0.492 |  Val. Acc: 80.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msNEnk9rk95X"
      },
      "source": [
        "def predict(model, iterator, criterion):\r\n",
        "    \r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    final_outputs = []  \r\n",
        "    test_id = []  \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for batch in iterator:\r\n",
        "            text, text_lengths = batch.text\r\n",
        "            predictions = model(text,text_lengths).squeeze(1)\r\n",
        "            predictions = predictions.argmax(1, keepdim = True) \r\n",
        "                                   \r\n",
        "            final_outputs+=predictions.view(-1).cpu().data.numpy().tolist()\r\n",
        "            test_id+=batch.ID.view(-1).cpu().numpy().tolist()\r\n",
        "    return test_id,final_outputs"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9bZci0Vk_g6"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\r\n",
        "\r\n",
        "test_,pred= predict(model,test_iterator, criterion)\r\n",
        "test_ = [ID.vocab.itos[i] for i in test_]"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28oMng1ulHN-"
      },
      "source": [
        "submission = pd.DataFrame({'ID':test_,'label':pred})\r\n",
        "submission.label = submission.label.replace({2:0, 0:1, 1: -1})\r\n",
        "submission.to_csv('gru.csv',index=False)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0mflV8u0puL",
        "outputId": "d64ce92c-ef3b-48e6-98ec-c7fd1af10c9c"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model,valid_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.496 | Test Acc: 79.06%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}